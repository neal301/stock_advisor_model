{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langgraph.graph import MessagesState\n",
    "from typing import Literal\n",
    "from typing_extensions import TypedDict, Annotated\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "import os\n",
    "import ast\n",
    "from langchain_community.tools.yahoo_finance_news import YahooFinanceNewsTool\n",
    "\n",
    "\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"]=\"6d440529fad24ffc8aef6d5f9ef52593\"\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"]=\"https://aiall9596864698.openai.azure.com/openai/deployments/gpt-4o/chat/completions?api-version=2024-08-01-preview\"\n",
    "os.environ[\"ALPHAVANTAGE_API_KEY\"]=\"5TW2G5K4N9GKMGRD\"\n",
    "\n",
    "embeddings = AzureOpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\",\n",
    "    azure_endpoint='https://aiall9596864698.cognitiveservices.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2023-05-15',\n",
    "    api_key='6d440529fad24ffc8aef6d5f9ef52593',\n",
    "    openai_api_version=\"2024-07-01-preview\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(MessagesState):\n",
    "    next: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChromaRetrieverTool:\n",
    "    def __init__(self, directory, collection, embedding, llm):\n",
    "        self.directory = directory\n",
    "        self.collection = collection\n",
    "        self.embedding = embedding\n",
    "        self.llm = llm\n",
    "\n",
    "    def initiate_retriever(self):\n",
    "        metadata_field_info = [\n",
    "            \n",
    "            AttributeInfo(\n",
    "                name=\"company\",\n",
    "                description=\"The name of the company\",\n",
    "                type=\"string or list[string]\",\n",
    "            ),\n",
    "            ]\n",
    "        \n",
    "        document_content_description = \"Chunked content of the 10-k filing\"\n",
    "\n",
    "        self.vector_store = Chroma(\n",
    "            collection_name=self.collection,\n",
    "            persist_directory=self.directory,\n",
    "            embedding_function=self.embedding\n",
    "        )\n",
    "\n",
    "        self.retriever=SelfQueryRetriever.from_llm(\n",
    "            self.llm,\n",
    "            self.vector_store,\n",
    "            document_content_description,\n",
    "            metadata_field_info,\n",
    "            verbose=True\n",
    "        )\n",
    "\n",
    "        self.retriever_tool=create_retriever_tool(\n",
    "            self.retriever,\n",
    "            '10-k document retriever',\n",
    "            'Query a retriever to get 10-k document information',\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "members = [\"tenk_expert\", \"financial_news\"]\n",
    "options = members + [\"FINISH\"]\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are a supervisor tasked with managing a conversation between the\"\n",
    "    f\" following workers: {members}. Given the following user request,\"\n",
    "    \" respond with the worker to act next. Each worker will perform a\"\n",
    "    \" task and respond with their results and status. When finished,\"\n",
    "    \" respond with FINISH. \"\n",
    ")\n",
    "\n",
    "\n",
    "class Router(TypedDict):\n",
    "    \"\"\"Worker to route to next. If no workers needed, route to FINISH.\"\"\"\n",
    "\n",
    "    next: Literal[*options]\n",
    "\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    azure_deployment=\"gpt-4o\",  # or your deployment\n",
    "    api_version=\"2024-08-01-preview\",  # or your api version\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    )\n",
    "\n",
    "def supervisor_node(state: AgentState) -> AgentState:\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "    ] + state[\"messages\"]\n",
    "    response = llm.with_structured_output(Router).invoke(messages)\n",
    "    next_ = response[\"next\"]\n",
    "    if next_ == \"FINISH\":\n",
    "        next_ = END\n",
    "\n",
    "    return {\"next\": next_}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x206739a8050>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "chroma_retriever = ChromaRetrieverTool(directory=\"../data/chroma_langchain_db_test\", collection=\"test_collection\", embedding=embeddings, llm=llm)\n",
    "chroma_retriever.initiate_retriever()\n",
    "\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "@tool(response_format=\"content_and_artifact\")\n",
    "def retrieve(query: str):\n",
    "    \"\"\"Retrieve information related to a query.\"\"\"\n",
    "    retrieved_docs = chroma_retriever.retriever.invoke(query)\n",
    "    serialized = \"\\n\\n\".join(\n",
    "        (f\"Source: {doc.metadata}\\n\" f\"Content: {doc.page_content}\")\n",
    "        for doc in retrieved_docs\n",
    "    )\n",
    "    return serialized, retrieved_docs\n",
    "\n",
    "tenk_agent = create_react_agent(\n",
    "    llm, tools=[retrieve], state_modifier=\"You are a retrieval agent for Ten K financial reports.\"\n",
    ")\n",
    "\n",
    "def tenk_node(state: AgentState) -> AgentState:\n",
    "    result = tenk_agent.invoke(state)\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            HumanMessage(content=result[\"messages\"][-1].content, name=\"tenk_expert\")\n",
    "        ]\n",
    "    }\n",
    "\n",
    "\n",
    "yahoo_news_agent = create_react_agent(llm, tools=[YahooFinanceNewsTool()], state_modifier=\"You are a news agent for Yahoo Finance.\")\n",
    "\n",
    "def yahoo_node(state: AgentState) -> AgentState:\n",
    "    result = yahoo_news_agent.invoke(state)\n",
    "    return {\n",
    "        \"messages\": [HumanMessage(content=result[\"messages\"][-1].content, name=\"financial_news\")]\n",
    "    }\n",
    "\n",
    "builder = StateGraph(AgentState)\n",
    "builder.add_edge(START, \"supervisor\")\n",
    "builder.add_node(\"supervisor\", supervisor_node)\n",
    "builder.add_node(\"tenk_expert\", tenk_node)\n",
    "builder.add_node(\"financial_news\", yahoo_node)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "for member in members:\n",
    "    # We want our workers to ALWAYS \"report back\" to the supervisor when done\n",
    "    builder.add_edge(member, \"supervisor\")\n",
    "\n",
    "# The supervisor populates the \"next\" field in the graph state\n",
    "# which routes to a node or finishes\n",
    "builder.add_conditional_edges(\"supervisor\", lambda state: state[\"next\"])\n",
    "# Finally, add entrypoint\n",
    "builder.add_edge(START, \"supervisor\")\n",
    "\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'supervisor': {'next': 'tenk_expert'}}\n",
      "----\n",
      "{'tenk_expert': {'messages': [HumanMessage(content='HUBS, in its 10-K report, highlights several risk factors and uncertainties that could impact its business and financial performance. The company operates in a highly competitive and rapidly changing environment, which introduces new risks and uncertainties over time. Key areas of focus include:\\n\\n1. **Forward-Looking Statements**: HUBS emphasizes that forward-looking statements in their report involve substantial risks and uncertainties. These statements are based on current expectations and projections about future events and trends, which may not be achieved due to various risk factors.\\n\\n2. **Market and Technological Evolution**: The company is focused on anticipating and addressing technological needs, including investments in artificial intelligence and machine learning. The ability to roll out upgrades and develop new applications is crucial to meet customer needs.\\n\\n3. **Investment Areas**: HUBS plans to invest in sales and marketing, research and development, customer service, and data center infrastructure. These investments are expected to support future growth but also come with inherent risks.\\n\\n4. **Corporate Culture and Workforce**: Maintaining a strong corporate culture and the ability to attract and retain talent are seen as critical to sustaining their market position.\\n\\nOverall, HUBS acknowledges the unpredictability of future events and the potential impact of various risk factors on their forward-looking statements.', additional_kwargs={}, response_metadata={}, name='tenk_expert', id='87689bb1-7b82-4a61-9e38-f1fbd9a07a9e')]}}\n",
      "----\n",
      "{'supervisor': {'next': 'financial_news'}}\n",
      "----\n",
      "{'financial_news': {'messages': [HumanMessage(content='Recent news about HubSpot (HUBS) highlights its potential as a strong investment in the big data sector and its current trading position:\\n\\n1. **Big Data Investment**: HubSpot is identified as one of the five big data stocks with strong revenue and earnings growth potential for 2025. This suggests that the company is well-positioned in the market and could offer significant returns to investors.\\n\\n2. **Golden Cross Event**: HubSpot has recently experienced a \"golden cross\" technical event, which is often seen as a bullish signal indicating potential upward momentum in the stock\\'s price. This could be a positive indicator for investors considering buying HUBS.\\n\\nThese insights suggest that HUBS is currently viewed positively in the market, with potential growth opportunities in the big data sector and favorable technical indicators. However, as always, investors should consider these factors in conjunction with their own risk tolerance and investment strategy.', additional_kwargs={}, response_metadata={}, name='financial_news', id='fb365dfa-cda0-4e4a-92d1-f6e0d3687a4c')]}}\n",
      "----\n",
      "{'supervisor': {'next': '__end__'}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for s in graph.stream(\n",
    "    {\"messages\": [(\"user\", \"How is HUBS doing for risk\")]}\n",
    "):\n",
    "    print(s)\n",
    "    print(\"----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_query(myquery):\n",
    "    final_state=graph.invoke(\n",
    "            {\"messages\": [HumanMessage(content=myquery)]},\n",
    "            {\"recursion_limit\": 100},\n",
    "            #return_intermediate_steps=True,\n",
    "        )\n",
    "    \n",
    "    system_prompt_one='You are a special agent who has the key purpose of inspecting a conversation and answering the original user query given the conversation.'\n",
    "    # Create the initial list\n",
    "    initial_messages = [\n",
    "        (\"system\", system_prompt_one)\n",
    "    ]\n",
    "    \n",
    "    initial_messages.extend(final_state['messages'])\n",
    "    final=llm.invoke(initial_messages)\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "myquery=\"How is HUBS doing for risk\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "this=run_query(myquery)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='HubSpot (HUBS) is currently being recognized in financial news for its promising position in the big data sector and its recent technical performance. The company is noted for its strong revenue and earnings growth potential in the big data market, which could enhance portfolio returns by 2025. Additionally, HUBS has experienced a \"golden cross\" technical event, a bullish signal indicating potential upward momentum in its stock price. These factors suggest a positive outlook for HUBS, potentially offsetting some of the risks associated with its competitive and rapidly changing business environment.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 111, 'prompt_tokens': 470, 'total_tokens': 581, 'completion_tokens_details': None, 'prompt_tokens_details': None}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_04751d0b65', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='run-437ef478-eb93-45e8-a7c6-a9a6437b5ed4-0', usage_metadata={'input_tokens': 470, 'output_tokens': 111, 'total_tokens': 581, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###JUNK\n",
    "AttributeInfo(\n",
    "                name=\"date\",\n",
    "                description=\"The date of 10-k filing\",\n",
    "                type=\"string or list[string]\",\n",
    "            ),\n",
    "            \n",
    "            AttributeInfo(\n",
    "                name=\"section\",\n",
    "                description=\"The section of the 10-k filing\",\n",
    "                type=\"string or list[string]\",\n",
    "            ),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Image\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from edgar import set_identity\n",
    "import pandas as pd\n",
    "import time\n",
    "from edgar import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[17:08:08] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Identity of the Edgar REST client set to <span style=\"font-weight: bold\">[</span>Neal Lockhart nhl3388@uncw.edu<span style=\"font-weight: bold\">]</span>           <a href=\"file:///home/neal/nealsfiles/stock_rag/stock_advisor_model/venv/lib/python3.10/site-packages/edgar/core.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">core.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/neal/nealsfiles/stock_rag/stock_advisor_model/venv/lib/python3.10/site-packages/edgar/core.py#161\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">161</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[17:08:08]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Identity of the Edgar REST client set to \u001b[1m[\u001b[0mNeal Lockhart nhl3388@uncw.edu\u001b[1m]\u001b[0m           \u001b]8;id=62101;file:///home/neal/nealsfiles/stock_rag/stock_advisor_model/venv/lib/python3.10/site-packages/edgar/core.py\u001b\\\u001b[2mcore.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=549466;file:///home/neal/nealsfiles/stock_rag/stock_advisor_model/venv/lib/python3.10/site-packages/edgar/core.py#161\u001b\\\u001b[2m161\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# must be set to comply with SEC regulations\n",
    "\n",
    "set_identity(\"Neal Lockhart nhl3388@uncw.edu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies = ['HUBS', 'SNOW', 'CRWD', 'ZS', 'NET', 'AMD', 'NVDA', 'BASE', 'NOW', 'S']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tenks = Company('S').get_filings(form = '10-K').latest(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = tenks[0].sections()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Risks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_risk_section(companies: list):\n",
    "\n",
    "    data = {\n",
    "        \"ticker\": [],\n",
    "        \"chunked_risk\": []\n",
    "    }\n",
    "    \n",
    "    for company in companies:\n",
    "        time.sleep(.1)\n",
    "        tenk = Company(company).get_filings(form=\"10-K\").latest(1)\n",
    "        raw_chunked_tenk = tenk.sections()\n",
    "        index_start = None\n",
    "        index_end = None\n",
    "        \n",
    "        for i in range(len(raw_chunked_tenk)):\n",
    "            if re.search(r\"item 1a.\\s*risk factors\", raw_chunked_tenk[i].lower()):\n",
    "                index_start=i\n",
    "            elif re.search(r\"item 1b.\\s*unresolved\", raw_chunked_tenk[i].lower()):\n",
    "                index_end=i\n",
    "                break\n",
    "\n",
    "        if index_start is None or index_end is None:\n",
    "            print(\"Warning: Could not find risk section for\", company)\n",
    "            continue\n",
    "        \n",
    "        risks = raw_chunked_tenk[index_start:index_end]\n",
    "\n",
    "        for i in range(len(risks)):\n",
    "            risks[i] = risks[i].lower()\n",
    "            risks[i] = risks[i].replace(\"\\n\",\" \")\n",
    "            risks[i] = risks[i].replace(\"•\", \" \")\n",
    "            risks[i] = risks[i].replace(\"table of contents\",\"\")\n",
    "            \n",
    "            data['ticker'].append(company)\n",
    "            data['chunked_risk'].append(risks[i])\n",
    "\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Management's Discussion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mgmt_discussion_section(companies: list):\n",
    "\n",
    "    data = {\n",
    "        \"ticker\": [],\n",
    "        \"chunked_mgmt_discussion\": []\n",
    "    }\n",
    "    \n",
    "    for company in companies:\n",
    "        time.sleep(.1)\n",
    "        tenk = Company(company).get_filings(form=\"10-K\").latest(1)\n",
    "        raw_chunked_tenk = tenk.sections()\n",
    "        index_start = None\n",
    "        index_end = None\n",
    "        \n",
    "        for i in range(len(raw_chunked_tenk)):\n",
    "            if re.search(r\"item 7.\\s*management\", raw_chunked_tenk[i].lower()):\n",
    "                index_start=i\n",
    "            elif re.search(r\"item 7a.\\s*(qualitative|quantitative)\", raw_chunked_tenk[i].lower()):\n",
    "                index_end=i\n",
    "                break\n",
    "\n",
    "        if index_start is None or index_end is None:\n",
    "            print(\"Warning: Could not find management's discussion section for\", company)\n",
    "            continue\n",
    "        \n",
    "        mgmt_discussion = raw_chunked_tenk[index_start:index_end]\n",
    "\n",
    "        for i in range(len(mgmt_discussion)):\n",
    "            mgmt_discussion[i] = mgmt_discussion[i].lower()\n",
    "            mgmt_discussion[i] = mgmt_discussion[i].replace(\"\\n\",\" \")\n",
    "            mgmt_discussion[i] = mgmt_discussion[i].replace(\"•\", \" \")\n",
    "            mgmt_discussion[i] = mgmt_discussion[i].replace(\"table of contents\",\"\")\n",
    "            mgmt_discussion[i] = \" \".join(mgmt_discussion[i].split())\n",
    "            \n",
    "            data['ticker'].append(company)\n",
    "            data['chunked_mgmt_discussion'].append(mgmt_discussion[i])\n",
    "\n",
    "    return pd.DataFrame(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
